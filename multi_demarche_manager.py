#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gestionnaire multid√©marche optimis√© int√©grant les am√©liorations des scripts fournis.

AM√âLIORATIONS PRINCIPALES :
1. R√©cup√©ration de sch√©ma optimis√©e avec cache
2. Filtrage c√¥t√© serveur pour la r√©cup√©ration des dossiers
3. Gestion d'erreur robuste avec fallback automatique
4. Cache intelligent des colonnes Grist
5. Parall√©lisation optimis√©e par d√©marche
"""

import os
import sys
import time
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

# Import des modules optimis√©s
from schema_utils import (
    get_demarche_schema_enhanced,
    smart_schema_update,
    detect_schema_changes
)
from queries_graphql import get_demarche_dossiers_filtered
from grist_processor_working_all import (
    GristClient, 
    ColumnCache,
    process_demarche_for_grist_optimized
)

@dataclass
class OptimizedSyncConfig:
    """Configuration optimis√©e pour la synchronisation"""
    # Param√®tres de performance
    use_robust_schema: bool = True
    enable_server_side_filtering: bool = True
    enable_column_cache: bool = True
    enable_parallel_processing: bool = True
    
    # Param√®tres de traitement
    batch_size: int = 100
    max_workers: int = 3
    schema_cache_duration: int = 3600  # 1 heure en secondes
    
    # Filtres par d√©faut
    default_filters: Dict[str, Any] = None

@dataclass 
class DemarcheProcessingResult:
    """R√©sultat du traitement d'une d√©marche"""
    demarche_number: int
    demarche_name: str
    success: bool
    dossiers_processed: int
    duration_seconds: float
    schema_optimized: bool = False
    filtering_optimized: bool = False
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class OptimizedMultiDemarcheManager:
    """
    Gestionnaire multid√©marche optimis√© avec les am√©liorations des scripts fournis.
    """
    
    def __init__(self, config_path: str = "multi_demarche_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        self.schema_cache = {}  # Cache des sch√©mas par d√©marche
        self.column_caches = {}  # Cache des colonnes Grist par document
        self.sync_config = OptimizedSyncConfig()
        
    def _load_config(self) -> Dict[str, Any]:
        """Charge la configuration avec gestion d'erreur robuste"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"‚ùå Fichier de configuration non trouv√© : {self.config_path}")
            return self._create_default_config()
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur dans le fichier de configuration : {e}")
            return self._create_default_config()
    
    def _create_default_config(self) -> Dict[str, Any]:
        """Cr√©e une configuration par d√©faut"""
        return {
            "grist": {
                "base_url": os.getenv("GRIST_BASE_URL", ""),
                "api_key": os.getenv("GRIST_API_KEY", ""),
                "doc_id": os.getenv("GRIST_DOC_ID", "")
            },
            "demarches": []
        }
    
    def get_schema_optimized(self, demarche_number: int, force_refresh: bool = False) -> Dict[str, Any]:
        """
        R√©cup√©ration optimis√©e du sch√©ma avec cache intelligent.
        
        AM√âLIORATION CL√âE : Cache des sch√©mas pour √©viter les requ√™tes r√©p√©t√©es
        """
        cache_key = str(demarche_number)
        current_time = time.time()
        
        # V√©rifier le cache si pas de rafra√Æchissement forc√©
        if not force_refresh and cache_key in self.schema_cache:
            cached_data = self.schema_cache[cache_key]
            if current_time - cached_data['timestamp'] < self.sync_config.schema_cache_duration:
                print(f"üìã Utilisation du sch√©ma en cache pour la d√©marche {demarche_number}")
                return cached_data['schema']
        
        # R√©cup√©ration optimis√©e avec la fonction enhanced
        print(f"üîÑ R√©cup√©ration optimis√©e du sch√©ma pour la d√©marche {demarche_number}")
        try:
            schema = get_demarche_schema_enhanced(
                demarche_number, 
                prefer_robust=self.sync_config.use_robust_schema
            )
            
            # Mise en cache
            self.schema_cache[cache_key] = {
                'schema': schema,
                'timestamp': current_time
            }
            
            print(f"‚úÖ Sch√©ma r√©cup√©r√© et mis en cache")
            return schema
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration du sch√©ma : {e}")
            # Tentative avec le cache expir√© si disponible
            if cache_key in self.schema_cache:
                print("üîÑ Utilisation du cache expir√© comme fallback")
                return self.schema_cache[cache_key]['schema']
            raise
    
    def get_dossiers_optimized(self, demarche_number: int, filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        R√©cup√©ration optimis√©e des dossiers avec filtrage c√¥t√© serveur.
        
        AM√âLIORATION CL√âE : Utilise le filtrage c√¥t√© serveur pour r√©duire la charge
        """
        if not self.sync_config.enable_server_side_filtering:
            # Fallback vers la m√©thode classique
            from queries_graphql import get_demarche_dossiers
            return get_demarche_dossiers(demarche_number)
        
        # Fusion des filtres par d√©faut et sp√©cifiques
        final_filters = {}
        if self.sync_config.default_filters:
            final_filters.update(self.sync_config.default_filters)
        if filters:
            final_filters.update(filters)
        
        print(f"üéØ R√©cup√©ration optimis√©e des dossiers avec filtres c√¥t√© serveur")
        if final_filters:
            print(f"   Filtres appliqu√©s : {list(final_filters.keys())}")
        
        try:
            dossiers = get_demarche_dossiers_filtered(
                demarche_number,
                date_debut=final_filters.get('date_debut'),
                date_fin=final_filters.get('date_fin'),
                groupes_instructeurs=final_filters.get('groupes_instructeurs'),
                statuts=final_filters.get('statuts')
            )
            
            print(f"‚úÖ {len(dossiers)} dossiers r√©cup√©r√©s avec filtrage optimis√©")
            return dossiers
            
        except Exception as e:
            print(f"‚ùå Erreur filtrage optimis√© : {e}")
            print("üîÑ Fallback vers la m√©thode classique")
            from queries_graphql import get_demarche_dossiers
            return get_demarche_dossiers(demarche_number)
    
    def get_column_cache(self, grist_doc_id: str) -> ColumnCache:
        """
        R√©cup√®re ou cr√©e un cache de colonnes pour un document Grist.
        
        AM√âLIORATION CL√âE : Cache partag√© des colonnes pour √©viter les requ√™tes r√©p√©t√©es
        """
        if grist_doc_id not in self.column_caches:
            grist_config = self.config['grist']
            client = GristClient(
                grist_config['base_url'],
                grist_config['api_key'],
                grist_doc_id
            )
            self.column_caches[grist_doc_id] = ColumnCache(client)
        
        return self.column_caches[grist_doc_id]
    
    def sync_demarche_optimized(self, demarche_config: Dict[str, Any]) -> DemarcheProcessingResult:
        """
        Synchronise une d√©marche avec toutes les optimisations activ√©es.
        
        INT√âGRATION COMPL√àTE des am√©liorations des scripts fournis.
        """
        demarche_number = demarche_config['number']
        demarche_name = demarche_config.get('name', f"D√©marche {demarche_number}")
        start_time = time.time()
        
        print(f"\nüöÄ Synchronisation optimis√©e : {demarche_name} (#{demarche_number})")
        
        try:
            # Configuration de l'environnement pour cette d√©marche
            self._configure_environment_for_demarche(demarche_config)
            
            # 1. R√âCUP√âRATION OPTIMIS√âE DU SCH√âMA
            schema_optimized = False
            try:
                schema = self.get_schema_optimized(demarche_number)
                schema_optimized = schema.get('metadata', {}).get('optimized', False)
                print(f"   üìã Sch√©ma : {'Optimis√©' if schema_optimized else 'Classique'}")
            except Exception as e:
                print(f"   ‚ùå Erreur sch√©ma : {e}")
                raise
            
            # 2. MISE √Ä JOUR INTELLIGENTE DES TABLES GRIST
            grist_config = self.config['grist']
            client = GristClient(
                grist_config['base_url'],
                grist_config['api_key'],
                grist_config['doc_id']
            )
            
            # Utiliser le cache de colonnes
            if self.sync_config.enable_column_cache:
                column_cache = self.get_column_cache(grist_config['doc_id'])
                client._column_cache = column_cache
            
            # Mise √† jour intelligente des tables
            update_result = smart_schema_update(
                client, 
                demarche_number, 
                use_robust_version=self.sync_config.use_robust_schema
            )
            
            if not update_result['success']:
                raise Exception(f"√âchec mise √† jour tables : {update_result.get('error')}")
            
            # 3. R√âCUP√âRATION OPTIMIS√âE DES DOSSIERS AVEC FILTRES
            filtering_optimized = False
            try:
                filters = self._build_filters_for_demarche(demarche_config)
                api_filters = self._convert_to_api_filters(filters) if filters else {}
                
                if api_filters:
                    filtering_optimized = True
                    print(f"   üéØ Filtrage c√¥t√© serveur activ√©")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erreur construction filtres : {e}")
                api_filters = {}
            
            # 4. TRAITEMENT PARALL√àLE OPTIMIS√â
            success = process_demarche_for_grist_optimized(
                client,
                demarche_number,
                parallel=self.sync_config.enable_parallel_processing,
                batch_size=self.sync_config.batch_size,
                max_workers=self.sync_config.max_workers,
                api_filters=api_filters  # Passer les filtres optimis√©s
            )
            
            duration = time.time() - start_time
            
            if success:
                print(f"   ‚úÖ Synchronisation r√©ussie en {duration:.1f}s")
            else:
                print(f"   ‚ùå √âchec de la synchronisation")
            
            return DemarcheProcessingResult(
                demarche_number=demarche_number,
                demarche_name=demarche_name,
                success=success,
                dossiers_processed=0,  # √Ä am√©liorer
                duration_seconds=duration,
                schema_optimized=schema_optimized,
                filtering_optimized=filtering_optimized
            )
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"Erreur : {str(e)}"
            print(f"   ‚ùå {error_msg}")
            
            return DemarcheProcessingResult(
                demarche_number=demarche_number,
                demarche_name=demarche_name,
                success=False,
                dossiers_processed=0,
                duration_seconds=duration,
                errors=[error_msg]
            )
    
    def _configure_environment_for_demarche(self, demarche_config: Dict[str, Any]):
        """Configure l'environnement pour une d√©marche sp√©cifique"""
        # Configuration des tokens API par d√©marche
        api_token = demarche_config.get('api_token')
        if api_token and not api_token.startswith('${'):
            os.environ['DEMARCHES_API_TOKEN'] = api_token
            
            # Force la mise √† jour dans queries_config
            import queries_config
            queries_config.API_TOKEN = api_token
            
            if hasattr(queries_config, 'DemarcheAPIConfig'):
                queries_config.DemarcheAPIConfig.set_organization(
                    demarche_config.get('organization', 'default')
                )
    
    def _build_filters_for_demarche(self, demarche_config: Dict[str, Any]) -> Dict[str, Any]:
        """Construit les filtres pour une d√©marche √† partir de sa configuration"""
        filters = {}
        
        # R√©cup√©rer les filtres depuis la configuration de la d√©marche
        if 'filters' in demarche_config:
            filters.update(demarche_config['filters'])
        
        # Ajouter les filtres par d√©faut si pas d√©j√† d√©finis
        if self.sync_config.default_filters:
            for key, value in self.sync_config.default_filters.items():
                if key not in filters:
                    filters[key] = value
        
        return filters
    
    def _convert_to_api_filters(self, filters: Dict[str, Any]) -> Dict[str, Any]:
        """Convertit les filtres de configuration vers le format API"""
        api_filters = {}
        
        # Mapping des cl√©s de configuration vers les cl√©s API
        key_mapping = {
            'date_debut': 'date_debut',
            'date_fin': 'date_fin', 
            'statuts': 'statuts',
            'groupes_instructeurs': 'groupes_instructeurs'
        }
        
        for config_key, api_key in key_mapping.items():
            if config_key in filters:
                api_filters[api_key] = filters[config_key]
        
        return api_filters
    
    def sync_all_optimized(self) -> List[DemarcheProcessingResult]:
        """
        Synchronise toutes les d√©marches activ√©es avec optimisations.
        """
        enabled_demarches = [d for d in self.config.get('demarches', []) if d.get('enabled', True)]
        
        if not enabled_demarches:
            print("‚ùå Aucune d√©marche activ√©e trouv√©e")
            return []
        
        print(f"üöÄ Synchronisation optimis√©e de {len(enabled_demarches)} d√©marches")
        print(f"   üìã Sch√©ma optimis√© : {'‚úÖ' if self.sync_config.use_robust_schema else '‚ùå'}")
        print(f"   üéØ Filtrage c√¥t√© serveur : {'‚úÖ' if self.sync_config.enable_server_side_filtering else '‚ùå'}")
        print(f"   üíæ Cache de colonnes : {'‚úÖ' if self.sync_config.enable_column_cache else '‚ùå'}")
        print(f"   ‚ö° Traitement parall√®le : {'‚úÖ' if self.sync_config.enable_parallel_processing else '‚ùå'}")
        
        results = []
        
        for i, demarche_config in enumerate(enabled_demarches, 1):
            print(f"\nüìã D√©marche {i}/{len(enabled_demarches)}")
            
            result = self.sync_demarche_optimized(demarche_config)
            results.append(result)
            
            # Pause entre d√©marches pour √©viter la surcharge
            if i < len(enabled_demarches):
                print("‚è∏Ô∏è Pause de 2 secondes...")
                time.sleep(2)
        
        self._print_optimization_summary(results)
        return results
    
    def _print_optimization_summary(self, results: List[DemarcheProcessingResult]):
        """Affiche un r√©sum√© des optimisations appliqu√©es"""
        if not results:
            return
        
        total_duration = sum(r.duration_seconds for r in results)
        success_count = sum(1 for r in results if r.success)
        schema_optimized_count = sum(1 for r in results if r.schema_optimized)
        filtering_optimized_count = sum(1 for r in results if r.filtering_optimized)
        
        print(f"\nüéØ R√âSUM√â DES OPTIMISATIONS")
        print(f"   ‚úÖ Succ√®s : {success_count}/{len(results)}")
        print(f"   ‚è±Ô∏è Dur√©e totale : {total_duration:.1f}s")
        print(f"   üìã Sch√©mas optimis√©s : {schema_optimized_count}/{len(results)}")
        print(f"   üéØ Filtrage optimis√© : {filtering_optimized_count}/{len(results)}")
        
        if success_count > 0:
            avg_duration = total_duration / len(results)
            print(f"   üìä Dur√©e moyenne : {avg_duration:.1f}s par d√©marche")

def main():
    """Point d'entr√©e principal avec support des optimisations"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Gestionnaire multid√©marche optimis√©")
    parser.add_argument('--config', default='multi_demarche_config.json', 
                       help='Chemin vers le fichier de configuration')
    parser.add_argument('--demarches', help='Num√©ros de d√©marches s√©par√©s par des virgules')
    parser.add_argument('--disable-schema-optimization', action='store_true',
                       help='D√©sactiver l\'optimisation du sch√©ma')
    parser.add_argument('--disable-server-filtering', action='store_true',
                       help='D√©sactiver le filtrage c√¥t√© serveur')
    parser.add_argument('--disable-column-cache', action='store_true',
                       help='D√©sactiver le cache des colonnes')
    parser.add_argument('--disable-parallel', action='store_true',
                       help='D√©sactiver le traitement parall√®le')
    parser.add_argument('--batch-size', type=int, default=100,
                       help='Taille des lots (d√©faut: 100)')
    parser.add_argument('--max-workers', type=int, default=3,
                       help='Nombre maximum de workers (d√©faut: 3)')
    
    args = parser.parse_args()
    
    # Cr√©er le gestionnaire
    manager = OptimizedMultiDemarcheManager(args.config)
    
    # Configuration des optimisations
    manager.sync_config.use_robust_schema = not args.disable_schema_optimization
    manager.sync_config.enable_server_side_filtering = not args.disable_server_filtering
    manager.sync_config.enable_column_cache = not args.disable_column_cache
    manager.sync_config.enable_parallel_processing = not args.disable_parallel
    manager.sync_config.batch_size = args.batch_size
    manager.sync_config.max_workers = args.max_workers
    
    # Activer le debug si demand√©
    if args.debug:
        import os
        os.environ['LOG_LEVEL'] = 'DEBUG'
        print("üêõ Mode debug activ√©")
    
    try:
        # V√©rifier que le fichier de configuration existe
        if not os.path.exists(args.config):
            print(f"‚ùå Fichier de configuration non trouv√© : {args.config}")
            print(f"üí° Cr√©ez le fichier {args.config} avec vos d√©marches")
            return 1
        
        print(f"‚úÖ Configuration charg√©e : {len(manager.config.get('demarches', []))} d√©marches trouv√©es")
        
        # Gestion des commandes compatibles avec l'ancien syst√®me
        if args.validate_only or args.dry_run:
            print("üîç Validation de la configuration...")
            try:
                # Test de validation simple
                enabled_demarches = [d for d in manager.config.get('demarches', []) if d.get('enabled', True)]
                if enabled_demarches:
                    print(f"‚úÖ Configuration valide : {len(enabled_demarches)} d√©marches activ√©es")
                    return 0
                else:
                    print("‚ùå Aucune d√©marche activ√©e trouv√©e")
                    return 1
            except Exception as e:
                print(f"‚ùå Configuration invalide : {e}")
                return 1
        
        elif args.sync_all:
            print("üîÑ Synchronisation de toutes les d√©marches (optimis√©)...")
            results = manager.sync_all_optimized()
            
        elif args.sync:
            # Compatibilit√© avec --sync NUMERO
            demarche_numbers = [int(args.sync.strip())]
            print(f"üéØ Synchronisation de la d√©marche : {demarche_numbers[0]}")
            
            # Filtrer les d√©marches √† traiter
            all_demarches = manager.config.get('demarches', [])
            specific_demarches = [d for d in all_demarches if d['number'] in demarche_numbers]
            
            if not specific_demarches:
                print(f"‚ùå D√©marche {demarche_numbers[0]} non trouv√©e dans la configuration")
                return 1
            
            results = []
            for demarche_config in specific_demarches:
                result = manager.sync_demarche_optimized(demarche_config)
                results.append(result)
        
        elif args.demarches:
            # Synchronisation de d√©marches sp√©cifiques (nouvelle syntaxe)
            try:
                demarche_numbers = [int(x.strip()) for x in args.demarches.split(',') if x.strip()]
                print(f"üéØ D√©marches s√©lectionn√©es : {demarche_numbers}")
                
                # Filtrer les d√©marches √† traiter
                all_demarches = manager.config.get('demarches', [])
                specific_demarches = [d for d in all_demarches if d['number'] in demarche_numbers]
                
                results = []
                for demarche_config in specific_demarches:
                    result = manager.sync_demarche_optimized(demarche_config)
                    results.append(result)
            except ValueError as e:
                print(f"‚ùå Erreur dans les num√©ros de d√©marches : {args.demarches}")
                return 1
        else:
            # Par d√©faut, synchroniser toutes les d√©marches
            print("üöÄ Synchronisation de toutes les d√©marches (aucune option sp√©cifi√©e)")
            results = manager.sync_all_optimized()
        
        # V√©rifier le succ√®s
        if 'results' in locals():
            success_count = sum(1 for r in results if r.success)
            if success_count > 0:
                print(f"\nüéâ Synchronisation termin√©e : {success_count} d√©marches trait√©es avec succ√®s")
                return 0
            else:
                print("\nüí• Aucune synchronisation r√©ussie")
                return 1
        else:
            return 0
            
    except Exception as e:
        print(f"üí• Erreur fatale : {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        else:
            print("üí° Utilisez --debug pour plus de d√©tails")
        return 1

if __name__ == "__main__":
    sys.exit(main())
