#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gestionnaire multidÃ©marche optimisÃ© intÃ©grant les amÃ©liorations des scripts fournis.

AMÃ‰LIORATIONS PRINCIPALES :
1. RÃ©cupÃ©ration de schÃ©ma optimisÃ©e avec cache
2. Filtrage cÃ´tÃ© serveur pour la rÃ©cupÃ©ration des dossiers
3. Gestion d'erreur robuste avec fallback automatique
4. Cache intelligent des colonnes Grist
5. ParallÃ©lisation optimisÃ©e par dÃ©marche
"""

import os
import sys
import time
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime

# Import des modules optimisÃ©s
from schema_utils import (
    get_demarche_schema_enhanced,
    smart_schema_update,
    detect_schema_changes
)
from queries_graphql import get_demarche_dossiers_filtered
from grist_processor_working_all import (
    GristClient, 
    ColumnCache,
    process_demarche_for_grist_optimized
)

@dataclass
class OptimizedSyncConfig:
    """Configuration optimisÃ©e pour la synchronisation"""
    # ParamÃ¨tres de performance
    use_robust_schema: bool = True
    enable_server_side_filtering: bool = True
    enable_column_cache: bool = True
    enable_parallel_processing: bool = True
    
    # ParamÃ¨tres de traitement
    batch_size: int = 100
    max_workers: int = 3
    schema_cache_duration: int = 3600  # 1 heure en secondes
    
    # Filtres par dÃ©faut
    default_filters: Dict[str, Any] = None

@dataclass 
class DemarcheProcessingResult:
    """RÃ©sultat du traitement d'une dÃ©marche"""
    demarche_number: int
    demarche_name: str
    success: bool
    dossiers_processed: int
    duration_seconds: float
    schema_optimized: bool = False
    filtering_optimized: bool = False
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []

class OptimizedMultiDemarcheManager:
    """
    Gestionnaire multidÃ©marche optimisÃ© avec les amÃ©liorations des scripts fournis.
    """
    
    def __init__(self, config_path: str = "multi_demarche_config.json"):
        self.config_path = config_path
        self.config = self._load_config()
        self.schema_cache = {}  # Cache des schÃ©mas par dÃ©marche
        self.column_caches = {}  # Cache des colonnes Grist par document
        self.sync_config = OptimizedSyncConfig()
        
    def _load_config(self) -> Dict[str, Any]:
        """Charge la configuration avec gestion d'erreur robuste"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ Fichier de configuration non trouvÃ© : {self.config_path}")
            return self._create_default_config()
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur dans le fichier de configuration : {e}")
            return self._create_default_config()
    
    def _create_default_config(self) -> Dict[str, Any]:
        """CrÃ©e une configuration par dÃ©faut"""
        return {
            "grist": {
                "base_url": os.getenv("GRIST_BASE_URL", ""),
                "api_key": os.getenv("GRIST_API_KEY", ""),
                "doc_id": os.getenv("GRIST_DOC_ID", "")
            },
            "demarches": []
        }
    
    def get_schema_optimized(self, demarche_number: int, force_refresh: bool = False) -> Dict[str, Any]:
        """
        RÃ©cupÃ©ration optimisÃ©e du schÃ©ma avec cache intelligent.
        
        AMÃ‰LIORATION CLÃ‰E : Cache des schÃ©mas pour Ã©viter les requÃªtes rÃ©pÃ©tÃ©es
        """
        cache_key = str(demarche_number)
        current_time = time.time()
        
        # VÃ©rifier le cache si pas de rafraÃ®chissement forcÃ©
        if not force_refresh and cache_key in self.schema_cache:
            cached_data = self.schema_cache[cache_key]
            if current_time - cached_data['timestamp'] < self.sync_config.schema_cache_duration:
                print(f"ğŸ“‹ Utilisation du schÃ©ma en cache pour la dÃ©marche {demarche_number}")
                return cached_data['schema']
        
        # RÃ©cupÃ©ration optimisÃ©e avec la fonction enhanced
        print(f"ğŸ”„ RÃ©cupÃ©ration optimisÃ©e du schÃ©ma pour la dÃ©marche {demarche_number}")
        try:
            schema = get_demarche_schema_enhanced(
                demarche_number, 
                prefer_robust=self.sync_config.use_robust_schema
            )
            
            # Mise en cache
            self.schema_cache[cache_key] = {
                'schema': schema,
                'timestamp': current_time
            }
            
            print(f"âœ… SchÃ©ma rÃ©cupÃ©rÃ© et mis en cache")
            return schema
            
        except Exception as e:
            print(f"âŒ Erreur lors de la rÃ©cupÃ©ration du schÃ©ma : {e}")
            # Tentative avec le cache expirÃ© si disponible
            if cache_key in self.schema_cache:
                print("ğŸ”„ Utilisation du cache expirÃ© comme fallback")
                return self.schema_cache[cache_key]['schema']
            raise
    
    def get_dossiers_optimized(self, demarche_number: int, filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        RÃ©cupÃ©ration optimisÃ©e des dossiers avec filtrage cÃ´tÃ© serveur.
        
        AMÃ‰LIORATION CLÃ‰E : Utilise le filtrage cÃ´tÃ© serveur pour rÃ©duire la charge
        """
        if not self.sync_config.enable_server_side_filtering:
            # Fallback vers la mÃ©thode classique
            from queries_graphql import get_demarche_dossiers
            return get_demarche_dossiers(demarche_number)
        
        # Fusion des filtres par dÃ©faut et spÃ©cifiques
        final_filters = {}
        if self.sync_config.default_filters:
            final_filters.update(self.sync_config.default_filters)
        if filters:
            final_filters.update(filters)
        
        print(f"ğŸ¯ RÃ©cupÃ©ration optimisÃ©e des dossiers avec filtres cÃ´tÃ© serveur")
        if final_filters:
            print(f"   Filtres appliquÃ©s : {list(final_filters.keys())}")
        
        try:
            dossiers = get_demarche_dossiers_filtered(
                demarche_number,
                date_debut=final_filters.get('date_debut'),
                date_fin=final_filters.get('date_fin'),
                groupes_instructeurs=final_filters.get('groupes_instructeurs'),
                statuts=final_filters.get('statuts')
            )
            
            print(f"âœ… {len(dossiers)} dossiers rÃ©cupÃ©rÃ©s avec filtrage optimisÃ©")
            return dossiers
            
        except Exception as e:
            print(f"âŒ Erreur filtrage optimisÃ© : {e}")
            print("ğŸ”„ Fallback vers la mÃ©thode classique")
            from queries_graphql import get_demarche_dossiers
            return get_demarche_dossiers(demarche_number)
    
    def get_column_cache(self, grist_doc_id: str) -> ColumnCache:
        """
        RÃ©cupÃ¨re ou crÃ©e un cache de colonnes pour un document Grist.
        
        AMÃ‰LIORATION CLÃ‰E : Cache partagÃ© des colonnes pour Ã©viter les requÃªtes rÃ©pÃ©tÃ©es
        """
        if grist_doc_id not in self.column_caches:
            grist_config = self.config['grist']
            client = GristClient(
                grist_config['base_url'],
                grist_config['api_key'],
                grist_doc_id
            )
            self.column_caches[grist_doc_id] = ColumnCache(client)
        
        return self.column_caches[grist_doc_id]
    
    def sync_demarche_optimized(self, demarche_config: Dict[str, Any]) -> DemarcheProcessingResult:
        """
        Synchronise une dÃ©marche avec toutes les optimisations activÃ©es.
        
        INTÃ‰GRATION COMPLÃˆTE des amÃ©liorations des scripts fournis.
        """
        demarche_number = demarche_config['number']
        demarche_name = demarche_config.get('name', f"DÃ©marche {demarche_number}")
        start_time = time.time()
        
        print(f"\nğŸš€ Synchronisation optimisÃ©e : {demarche_name} (#{demarche_number})")
        
        try:
            # Configuration de l'environnement pour cette dÃ©marche
            self._configure_environment_for_demarche(demarche_config)
            
            # 1. RÃ‰CUPÃ‰RATION OPTIMISÃ‰E DU SCHÃ‰MA
            schema_optimized = False
            try:
                schema = self.get_schema_optimized(demarche_number)
                schema_optimized = schema.get('metadata', {}).get('optimized', False)
                print(f"   ğŸ“‹ SchÃ©ma : {'OptimisÃ©' if schema_optimized else 'Classique'}")
            except Exception as e:
                print(f"   âŒ Erreur schÃ©ma : {e}")
                raise
            
            # 2. MISE Ã€ JOUR INTELLIGENTE DES TABLES GRIST
            grist_config = self.config['grist']
            client = GristClient(
                grist_config['base_url'],
                grist_config['api_key'],
                grist_config['doc_id']
            )
            
            # Utiliser le cache de colonnes
            if self.sync_config.enable_column_cache:
                column_cache = self.get_column_cache(grist_config['doc_id'])
                client._column_cache = column_cache
            
            # Mise Ã  jour intelligente des tables
            update_result = smart_schema_update(
                client, 
                demarche_number, 
                use_robust_version=self.sync_config.use_robust_schema
            )
            
            if not update_result['success']:
                raise Exception(f"Ã‰chec mise Ã  jour tables : {update_result.get('error')}")
            
            # 3. RÃ‰CUPÃ‰RATION OPTIMISÃ‰E DES DOSSIERS AVEC FILTRES
            filtering_optimized = False
            try:
                filters = self._build_filters_for_demarche(demarche_config)
                api_filters = self._convert_to_api_filters(filters) if filters else {}
                
                if api_filters:
                    filtering_optimized = True
                    print(f"   ğŸ¯ Filtrage cÃ´tÃ© serveur activÃ©")
                
            except Exception as e:
                print(f"   âš ï¸ Erreur construction filtres : {e}")
                api_filters = {}
            
            # 4. TRAITEMENT PARALLÃˆLE OPTIMISÃ‰
            success = process_demarche_for_grist_optimized(
                client,
                demarche_number,
                parallel=self.sync_config.enable_parallel_processing,
                batch_size=self.sync_config.batch_size,
                max_workers=self.sync_config.max_workers,
                api_filters=api_filters  # Passer les filtres optimisÃ©s
            )
            
            duration = time.time() - start_time
            
            if success:
                print(f"   âœ… Synchronisation rÃ©ussie en {duration:.1f}s")
            else:
                print(f"   âŒ Ã‰chec de la synchronisation")
            
            return DemarcheProcessingResult(
                demarche_number=demarche_number,
                demarche_name=demarche_name,
                success=success,
                dossiers_processed=0,  # Ã€ amÃ©liorer
                duration_seconds=duration,
                schema_optimized=schema_optimized,
                filtering_optimized=filtering_optimized
            )
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"Erreur : {str(e)}"
            print(f"   âŒ {error_msg}")
            
            return DemarcheProcessingResult(
                demarche_number=demarche_number,
                demarche_name=demarche_name,
                success=False,
                dossiers_processed=0,
                duration_seconds=duration,
                errors=[error_msg]
            )
    
    def _configure_environment_for_demarche(self, demarche_config: Dict[str, Any]):
        """Configure l'environnement pour une dÃ©marche spÃ©cifique"""
        # Configuration des tokens API par dÃ©marche
        api_token = demarche_config.get('api_token')
        if api_token and not api_token.startswith('${'):
            os.environ['DEMARCHES_API_TOKEN'] = api_token
            
            # Force la mise Ã  jour dans queries_config
            import queries_config
            queries_config.API_TOKEN = api_token
            
            if hasattr(queries_config, 'DemarcheAPIConfig'):
                queries_config.DemarcheAPIConfig.set_organization(
                    demarche_config.get('organization', 'default')
                )
    
    def _build_filters_for_demarche(self, demarche_config: Dict[str, Any]) -> Dict[str, Any]:
        """Construit les filtres pour une dÃ©marche Ã  partir de sa configuration"""
        filters = {}
        
        # RÃ©cupÃ©rer les filtres depuis la configuration de la dÃ©marche
        if 'filters' in demarche_config:
            filters.update(demarche_config['filters'])
        
        # Ajouter les filtres par dÃ©faut si pas dÃ©jÃ  dÃ©finis
        if self.sync_config.default_filters:
            for key, value in self.sync_config.default_filters.items():
                if key not in filters:
                    filters[key] = value
        
        return filters
    
    def _convert_to_api_filters(self, filters: Dict[str, Any]) -> Dict[str, Any]:
        """Convertit les filtres de configuration vers le format API"""
        api_filters = {}
        
        # Mapping des clÃ©s de configuration vers les clÃ©s API
        key_mapping = {
            'date_debut': 'date_debut',
            'date_fin': 'date_fin', 
            'statuts': 'statuts',
            'groupes_instructeurs': 'groupes_instructeurs'
        }
        
        for config_key, api_key in key_mapping.items():
            if config_key in filters:
                api_filters[api_key] = filters[config_key]
        
        return api_filters
    
    def sync_all_optimized(self) -> List[DemarcheProcessingResult]:
        """
        Synchronise toutes les dÃ©marches activÃ©es avec optimisations.
        """
        enabled_demarches = [d for d in self.config.get('demarches', []) if d.get('enabled', True)]
        
        if not enabled_demarches:
            print("âŒ Aucune dÃ©marche activÃ©e trouvÃ©e")
            return []
        
        print(f"ğŸš€ Synchronisation optimisÃ©e de {len(enabled_demarches)} dÃ©marches")
        print(f"   ğŸ“‹ SchÃ©ma optimisÃ© : {'âœ…' if self.sync_config.use_robust_schema else 'âŒ'}")
        print(f"   ğŸ¯ Filtrage cÃ´tÃ© serveur : {'âœ…' if self.sync_config.enable_server_side_filtering else 'âŒ'}")
        print(f"   ğŸ’¾ Cache de colonnes : {'âœ…' if self.sync_config.enable_column_cache else 'âŒ'}")
        print(f"   âš¡ Traitement parallÃ¨le : {'âœ…' if self.sync_config.enable_parallel_processing else 'âŒ'}")
        
        results = []
        
        for i, demarche_config in enumerate(enabled_demarches, 1):
            print(f"\nğŸ“‹ DÃ©marche {i}/{len(enabled_demarches)}")
            
            result = self.sync_demarche_optimized(demarche_config)
            results.append(result)
            
            # Pause entre dÃ©marches pour Ã©viter la surcharge
            if i < len(enabled_demarches):
                print("â¸ï¸ Pause de 2 secondes...")
                time.sleep(2)
        
        self._print_optimization_summary(results)
        return results
    
    def _print_optimization_summary(self, results: List[DemarcheProcessingResult]):
        """Affiche un rÃ©sumÃ© des optimisations appliquÃ©es"""
        if not results:
            return
        
        total_duration = sum(r.duration_seconds for r in results)
        success_count = sum(1 for r in results if r.success)
        schema_optimized_count = sum(1 for r in results if r.schema_optimized)
        filtering_optimized_count = sum(1 for r in results if r.filtering_optimized)
        
        print(f"\nğŸ¯ RÃ‰SUMÃ‰ DES OPTIMISATIONS")
        print(f"   âœ… SuccÃ¨s : {success_count}/{len(results)}")
        print(f"   â±ï¸ DurÃ©e totale : {total_duration:.1f}s")
        print(f"   ğŸ“‹ SchÃ©mas optimisÃ©s : {schema_optimized_count}/{len(results)}")
        print(f"   ğŸ¯ Filtrage optimisÃ© : {filtering_optimized_count}/{len(results)}")
        
        if success_count > 0:
            avg_duration = total_duration / len(results)
            print(f"   ğŸ“Š DurÃ©e moyenne : {avg_duration:.1f}s par dÃ©marche")

def main():
    """Point d'entrÃ©e principal avec support des optimisations"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Gestionnaire multidÃ©marche optimisÃ©")
    parser.add_argument('--config', default='multi_demarche_config.json', 
                       help='Chemin vers le fichier de configuration')
    parser.add_argument('--demarches', help='NumÃ©ros de dÃ©marches sÃ©parÃ©s par des virgules')
    parser.add_argument('--disable-schema-optimization', action='store_true',
                       help='DÃ©sactiver l\'optimisation du schÃ©ma')
    parser.add_argument('--disable-server-filtering', action='store_true',
                       help='DÃ©sactiver le filtrage cÃ´tÃ© serveur')
    parser.add_argument('--disable-column-cache', action='store_true',
                       help='DÃ©sactiver le cache des colonnes')
    parser.add_argument('--disable-parallel', action='store_true',
                       help='DÃ©sactiver le traitement parallÃ¨le')
    parser.add_argument('--batch-size', type=int, default=100,
                       help='Taille des lots (dÃ©faut: 100)')
    parser.add_argument('--max-workers', type=int, default=3,
                       help='Nombre maximum de workers (dÃ©faut: 3)')
    
    args = parser.parse_args()
    
    # CrÃ©er le gestionnaire
    manager = OptimizedMultiDemarcheManager(args.config)
    
    # Configuration des optimisations
    manager.sync_config.use_robust_schema = not args.disable_schema_optimization
    manager.sync_config.enable_server_side_filtering = not args.disable_server_filtering
    manager.sync_config.enable_column_cache = not args.disable_column_cache
    manager.sync_config.enable_parallel_processing = not args.disable_parallel
    manager.sync_config.batch_size = args.batch_size
    manager.sync_config.max_workers = args.max_workers
    
    # Activer le debug si demandÃ©
    if args.debug:
        import os
        os.environ['LOG_LEVEL'] = 'DEBUG'
        print("ğŸ› Mode debug activÃ©")
    
    try:
        # VÃ©rifier que le fichier de configuration existe
        if not os.path.exists(args.config):
            print(f"âŒ Fichier de configuration non trouvÃ© : {args.config}")
            print(f"ğŸ’¡ CrÃ©ez le fichier {args.config} avec vos dÃ©marches")
            return 1
        
        print(f"âœ… Configuration chargÃ©e : {len(manager.config.get('demarches', []))} dÃ©marches trouvÃ©es")
        
        # Gestion des commandes compatibles avec l'ancien systÃ¨me
        if args.validate_only or args.dry_run:
            print("ğŸ” Validation de la configuration...")
            try:
                # Test de validation simple
                enabled_demarches = [d for d in manager.config.get('demarches', []) if d.get('enabled', True)]
                if enabled_demarches:
                    print(f"âœ… Configuration valide : {len(enabled_demarches)} dÃ©marches activÃ©es")
                    return 0
                else:
                    print("âŒ Aucune dÃ©marche activÃ©e trouvÃ©e")
                    return 1
            except Exception as e:
                print(f"âŒ Configuration invalide : {e}")
                return 1
        
        elif args.sync_all:
            print("ğŸ”„ Synchronisation de toutes les dÃ©marches (optimisÃ©)...")
            results = manager.sync_all_optimized()
            
        elif args.sync:
            # CompatibilitÃ© avec --sync NUMERO
            demarche_numbers = [int(args.sync.strip())]
            print(f"ğŸ¯ Synchronisation de la dÃ©marche : {demarche_numbers[0]}")
            
            # Filtrer les dÃ©marches Ã  traiter
            all_demarches = manager.config.get('demarches', [])
            specific_demarches = [d for d in all_demarches if d['number'] in demarche_numbers]
            
            if not specific_demarches:
                print(f"âŒ DÃ©marche {demarche_numbers[0]} non trouvÃ©e dans la configuration")
                return 1
            
            results = []
            for demarche_config in specific_demarches:
                result = manager.sync_demarche_optimized(demarche_config)
                results.append(result)
        
        elif args.demarches:
            # Synchronisation de dÃ©marches spÃ©cifiques (nouvelle syntaxe)
            try:
                demarche_numbers = [int(x.strip()) for x in args.demarches.split(',') if x.strip()]
                print(f"ğŸ¯ DÃ©marches sÃ©lectionnÃ©es : {demarche_numbers}")
                
                # Filtrer les dÃ©marches Ã  traiter
                all_demarches = manager.config.get('demarches', [])
                specific_demarches = [d for d in all_demarches if d['number'] in demarche_numbers]
                
                results = []
                for demarche_config in specific_demarches:
                    result = manager.sync_demarche_optimized(demarche_config)
                    results.append(result)
            except ValueError as e:
                print(f"âŒ Erreur dans les numÃ©ros de dÃ©marches : {args.demarches}")
                return 1
        else:
            # Par dÃ©faut, synchroniser toutes les dÃ©marches
            print("ğŸš€ Synchronisation de toutes les dÃ©marches (aucune option spÃ©cifiÃ©e)")
            results = manager.sync_all_optimized()
        
        # VÃ©rifier le succÃ¨s
        if 'results' in locals():
            success_count = sum(1 for r in results if r.success)
            if success_count > 0:
                print(f"\nğŸ‰ Synchronisation terminÃ©e : {success_count} dÃ©marches traitÃ©es avec succÃ¨s")
                return 0
            else:
                print("\nğŸ’¥ Aucune synchronisation rÃ©ussie")
                return 1
        else:
            return 0
            
    except Exception as e:
        print(f"ğŸ’¥ Erreur fatale : {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        else:
            print("ğŸ’¡ Utilisez --debug pour plus de dÃ©tails")
        return 1

if __name__ == "__main__":
    sys.exit(main())
