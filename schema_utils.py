"""
Module d'utilitaires pour r√©cup√©rer et traiter le sch√©ma complet d'une d√©marche
√† partir de l'API D√©marches Simplifi√©es, pour la cr√©ation correcte de tables Grist.

VERSION AM√âLIOR√âE - Compatible avec le code existant
Ajoute des fonctions optimis√©es tout en gardant les fonctions existantes
"""

import requests
import json
from typing import Dict, List, Any, Tuple, Optional, Set

# Importer les configurations n√©cessaires
from queries_config import API_TOKEN, API_URL

# ========================================
# FONCTIONS EXISTANTES - GARD√âES INTACTES
# ========================================

def get_demarche_schema(demarche_number):
    """
    R√©cup√®re le sch√©ma complet d'une d√©marche avec tous ses descripteurs de champs,
    sans d√©pendre des dossiers existants.
    
    FONCTION EXISTANTE - GARD√âE POUR COMPATIBILIT√â
    
    Args:
        demarche_number: Num√©ro de la d√©marche
        
    Returns:
        dict: Structure compl√®te des descripteurs de champs et d'annotations
    """
    if not API_TOKEN:
        raise ValueError("Le token d'API n'est pas configur√©. D√©finissez DEMARCHES_API_TOKEN dans le fichier .env")
    
    # Requ√™te GraphQL sp√©cifique pour r√©cup√©rer les descripteurs de champs
    query = """
    query getDemarcheSchema($demarcheNumber: Int!) {
        demarche(number: $demarcheNumber) {
            id
            number
            title
            activeRevision {
                id
                champDescriptors {
                    ...ChampDescriptorFragment
                    ... on RepetitionChampDescriptor {
                        champDescriptors {
                            ...ChampDescriptorFragment
                        }
                    }
                }
                annotationDescriptors {
                    ...ChampDescriptorFragment
                    ... on RepetitionChampDescriptor {
                        champDescriptors {
                            ...ChampDescriptorFragment
                        }
                    }
                }
            }
        }
    }
    
    fragment ChampDescriptorFragment on ChampDescriptor {
        __typename
        id
        type
        label
        description
        required
        ... on DropDownListChampDescriptor {
            options
            otherOption
        }
        ... on MultipleDropDownListChampDescriptor {
            options
        }
        ... on LinkedDropDownListChampDescriptor {
            options
        }
        ... on PieceJustificativeChampDescriptor {
            fileTemplate {
                filename
            }
        }
        ... on ExplicationChampDescriptor {
            collapsibleExplanationEnabled
            collapsibleExplanationText
        }
    }
    """
    
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    # Ex√©cuter la requ√™te
    response = requests.post(
        API_URL,
        json={"query": query, "variables": {"demarcheNumber": int(demarche_number)}},
        headers=headers
    )
    
    # V√©rifier le code de statut
    response.raise_for_status()
    
    # Analyser la r√©ponse JSON
    result = response.json()
    
    # V√©rifier les erreurs
    if "errors" in result:
        filtered_errors = []
        for error in result["errors"]:
            error_message = error.get("message", "")
            if "permissions" not in error_message and "hidden due to permissions" not in error_message:
                filtered_errors.append(error_message)
        
        if filtered_errors:
            raise Exception(f"GraphQL errors: {', '.join(filtered_errors)}")
    
    # Si aucune donn√©e n'est retourn√©e, c'est un probl√®me
    if not result.get("data") or not result["data"].get("demarche"):
        raise Exception(f"Aucune donn√©e de d√©marche trouv√©e pour le num√©ro {demarche_number}")
    
    demarche = result["data"]["demarche"]
    
    # V√©rifier que activeRevision existe
    if not demarche.get("activeRevision"):
        raise Exception(f"Aucune r√©vision active trouv√©e pour la d√©marche {demarche_number}")
    
    return demarche

def get_problematic_descriptor_ids_from_schema(demarche_schema):
    """
    Extrait les IDs des descripteurs probl√©matiques (HeaderSection, Explication)
    directement depuis le sch√©ma de la d√©marche.
    
    FONCTION EXISTANTE - GARD√âE POUR COMPATIBILIT√â
    
    Args:
        demarche_schema: Sch√©ma de la d√©marche r√©cup√©r√© via get_demarche_schema
        
    Returns:
        set: Ensemble des IDs probl√©matiques √† filtrer
    """
    problematic_ids = set()
    
    # Fonction r√©cursive pour explorer les descripteurs
    def explore_descriptors(descriptors):
        for descriptor in descriptors:
            if descriptor.get("__typename") in ["HeaderSectionChampDescriptor", "ExplicationChampDescriptor"] or \
               descriptor.get("type") in ["header_section", "explication"]:
                problematic_ids.add(descriptor.get("id"))
            
            # Explorer les descripteurs dans les blocs r√©p√©tables
            if descriptor.get("__typename") == "RepetitionChampDescriptor" and "champDescriptors" in descriptor:
                explore_descriptors(descriptor["champDescriptors"])
    
    # Explorer les descripteurs de champs et d'annotations
    if demarche_schema.get("activeRevision"):
        if "champDescriptors" in demarche_schema["activeRevision"]:
            explore_descriptors(demarche_schema["activeRevision"]["champDescriptors"])
        
        if "annotationDescriptors" in demarche_schema["activeRevision"]:
            explore_descriptors(demarche_schema["activeRevision"]["annotationDescriptors"])
    
    return problematic_ids

def create_columns_from_schema(demarche_schema):
    """
    Cr√©e les d√©finitions de colonnes √† partir du sch√©ma de la d√©marche,
    en filtrant les champs probl√©matiques (HeaderSection, Explication)
    
    FONCTION EXISTANTE - GARD√âE POUR COMPATIBILIT√â
    
    Args:
        demarche_schema: Sch√©ma de la d√©marche r√©cup√©r√© via get_demarche_schema
        
    Returns:
        dict: D√©finitions des colonnes pour toutes les tables
    """
    # IMPORT LOCAL pour √©viter la d√©pendance circulaire
    from grist_processor_working_all import normalize_column_name, log, log_verbose, log_error
    
    # R√©cup√©rer les IDs des descripteurs probl√©matiques √† filtrer
    problematic_ids = get_problematic_descriptor_ids_from_schema(demarche_schema)
    log(f"Identificateurs de {len(problematic_ids)} descripteurs probl√©matiques √† filtrer")
    
    # Fonction pour d√©terminer le type de colonne Grist
    def determine_column_type(champ_type, typename=None):
        """D√©termine le type de colonne Grist bas√© sur le type de champ DS"""
        type_mapping = {
            "text": "Text",
            "textarea": "Text", 
            "email": "Text",
            "phone": "Text",
            "number": "Numeric",
            "integer_number": "Int",
            "decimal_number": "Numeric",
            "date": "Date",
            "datetime": "DateTime",
            "yes_no": "Bool",
            "checkbox": "Bool",
            "drop_down_list": "Text",
            "multiple_drop_down_list": "Text",
            "linked_drop_down_list": "Text",
            "piece_justificative": "Text",
            "iban": "Text",
            "siret": "Text",
            "rna": "Text",
            "titre_identite": "Text",
            "address": "Text",
            "commune": "Text",
            "departement": "Text",
            "region": "Text",
            "pays": "Text",
            "carte": "Text",
            "repetition": "Text"
        }
        return type_mapping.get(champ_type, "Text")
    
    # Colonnes fixes pour la table des dossiers
    dossier_columns = [
        {"id": "dossier_id", "type": "Text"},
        {"id": "number", "type": "Int"},
        {"id": "state", "type": "Text"},
        {"id": "date_depot", "type": "DateTime"},
        {"id": "date_derniere_modification", "type": "DateTime"},
        {"id": "date_traitement", "type": "DateTime"},
        {"id": "demandeur_type", "type": "Text"},
        {"id": "demandeur_civilite", "type": "Text"},
        {"id": "demandeur_nom", "type": "Text"},
        {"id": "demandeur_prenom", "type": "Text"},
        {"id": "demandeur_email", "type": "Text"},
        {"id": "demandeur_siret", "type": "Text"},
        {"id": "entreprise_raison_sociale", "type": "Text"},
        {"id": "usager_email", "type": "Text"},
        {"id": "groupe_instructeur_id", "type": "Text"},
        {"id": "groupe_instructeur_number", "type": "Int"},
        {"id": "groupe_instructeur_label", "type": "Text"},
        {"id": "supprime_par_usager", "type": "Bool"},
        {"id": "date_suppression", "type": "DateTime"},
        {"id": "prenom_mandataire", "type": "Text"},
        {"id": "nom_mandataire", "type": "Text"},
        {"id": "depose_par_un_tiers", "type": "Bool"},
        {"id": "label_names", "type": "Text"},
        {"id": "labels_json", "type": "Text"}
    ]

    # Colonnes de base pour la table des champs
    champ_columns = [
        {"id": "dossier_number", "type": "Int"},
        {"id": "champ_id", "type": "Text"},
    ]
    
    # Colonnes de base pour la table des annotations
    annotation_columns = [
        {"id": "dossier_number", "type": "Int"},
    ]
    
    # Colonnes de base pour la table des blocs r√©p√©tables
    repetable_columns = [
        {"id": "dossier_number", "type": "Int"},
        {"id": "block_label", "type": "Text"},
        {"id": "block_row_index", "type": "Int"},
        {"id": "block_row_id", "type": "Text"},
        {"id": "field_name", "type": "Text"}  # Pour les champs cartographiques
    ]

    # Variables pour suivre la pr√©sence de blocs r√©p√©tables et champs carto
    has_repetable_blocks = False
    has_carto_fields = False

    # Traiter les descripteurs de champs
    if demarche_schema.get("activeRevision") and demarche_schema["activeRevision"].get("champDescriptors"):
        for descriptor in demarche_schema["activeRevision"]["champDescriptors"]:
            # Ignorer les types probl√©matiques
            if descriptor["__typename"] in ["HeaderSectionChampDescriptor", "ExplicationChampDescriptor"] or \
               descriptor.get("type") in ["header_section", "explication"] or \
               descriptor.get("id") in problematic_ids:
                continue
                
            champ_type = descriptor.get("type")
            champ_label = descriptor.get("label")
            
            # Traitement sp√©cial pour les blocs r√©p√©tables
            if descriptor.get("__typename") == "RepetitionChampDescriptor" and "champDescriptors" in descriptor:
                has_repetable_blocks = True
                
                # Traiter les sous-champs du bloc r√©p√©table
                for inner_descriptor in descriptor["champDescriptors"]:
                    inner_type = inner_descriptor.get("type")
                    inner_label = inner_descriptor.get("label")
                    
                    # D√©tecter les champs cartographiques
                    if inner_type == "carte":
                        has_carto_fields = True
                    
                    # Ajouter le champ normalis√© √† la table des blocs r√©p√©tables
                    normalized_label = normalize_column_name(inner_label)
                    column_type = determine_column_type(inner_type, inner_descriptor.get("__typename"))
                    
                    if not any(col["id"] == normalized_label for col in repetable_columns):
                        repetable_columns.append({
                            "id": normalized_label,
                            "type": column_type
                        })
            
            # D√©tecter les champs cartographiques au niveau principal
            elif champ_type == "carte":
                has_carto_fields = True
            
            # Ajouter le champ normalis√© √† la table des champs
            normalized_label = normalize_column_name(champ_label)
            column_type = determine_column_type(champ_type, descriptor.get("__typename"))
            
            if not any(col["id"] == normalized_label for col in champ_columns):
                champ_columns.append({
                    "id": normalized_label,
                    "type": column_type
                })

    # Traiter les descripteurs d'annotations
    if demarche_schema.get("activeRevision") and demarche_schema["activeRevision"].get("annotationDescriptors"):
        for descriptor in demarche_schema["activeRevision"]["annotationDescriptors"]:
            # Ignorer les types probl√©matiques
            if descriptor["__typename"] in ["HeaderSectionChampDescriptor", "ExplicationChampDescriptor"] or \
               descriptor.get("type") in ["header_section", "explication"] or \
               descriptor.get("id") in problematic_ids:
                continue
                
            champ_type = descriptor.get("type")
            champ_label = descriptor.get("label")
            
            # Pour les annotations, enlever le pr√©fixe "annotation_" pour le nom de colonne
            if champ_label.startswith("annotation_"):
                annotation_label = normalize_column_name(champ_label[11:])  # enlever "annotation_"
            else:
                annotation_label = normalize_column_name(champ_label)
            
            column_type = determine_column_type(champ_type, descriptor.get("__typename"))
            
            if not any(col["id"] == annotation_label for col in annotation_columns):
                annotation_columns.append({
                    "id": annotation_label,
                    "type": column_type
                })
    
    # Ajouter les colonnes sp√©cifiques pour les donn√©es g√©ographiques
    if has_carto_fields:
        geo_columns = [
            {"id": "geo_id", "type": "Text"},
            {"id": "geo_source", "type": "Text"},
            {"id": "geo_description", "type": "Text"},
            {"id": "geo_type", "type": "Text"},
            {"id": "geo_coordinates", "type": "Text"},
            {"id": "geo_wkt", "type": "Text"},
            {"id": "geo_commune", "type": "Text"},
            {"id": "geo_numero", "type": "Text"},
            {"id": "geo_section", "type": "Text"},
            {"id": "geo_prefixe", "type": "Text"},
            {"id": "geo_surface", "type": "Numeric"}
        ]
        
        # Ajouter aux blocs r√©p√©tables s'ils existent
        if has_repetable_blocks:
            for geo_col in geo_columns:
                if not any(col["id"] == geo_col["id"] for col in repetable_columns):
                    repetable_columns.append(geo_col)

    # Pr√©parer le r√©sultat
    result = {
        "dossier": dossier_columns,
        "champs": champ_columns,
        "annotations": annotation_columns,
        "has_repetable_blocks": has_repetable_blocks,
        "has_carto_fields": has_carto_fields
    }
    
    if has_repetable_blocks:
        result["repetable_rows"] = repetable_columns
    
    return result, problematic_ids

def update_grist_tables_from_schema(client, demarche_number, column_types, problematic_ids=None):
    """
    Met √† jour les tables Grist existantes en fonction du sch√©ma actuel de la d√©marche,
    en ajoutant les nouvelles colonnes sans supprimer les donn√©es existantes.
    
    FONCTION EXISTANTE - GARD√âE POUR COMPATIBILIT√â
    """
    # IMPORT LOCAL pour √©viter la d√©pendance circulaire
    from grist_processor_working_all import log, log_verbose, log_error
    
    log(f"Mise √† jour des tables Grist pour la d√©marche {demarche_number} d'apr√®s le sch√©ma...")
    
    try:
        # Variables de suivi des indicateurs de pr√©sence
        has_repetable_blocks = column_types.get("has_repetable_blocks", False)
        has_carto_fields = column_types.get("has_carto_fields", False)
        
        # D√©finir les IDs de tables
        dossier_table_id = f"Demarche_{demarche_number}_dossiers"
        champ_table_id = f"Demarche_{demarche_number}_champs"
        annotation_table_id = f"Demarche_{demarche_number}_annotations"
        repetable_table_id = f"Demarche_{demarche_number}_repetable_rows" if has_repetable_blocks else None
        
        # R√©cup√©rer les tables existantes
        existing_tables_response = client.list_tables()
        existing_tables = existing_tables_response.get('tables', [])
        
        # Rechercher les tables existantes
        dossier_table = None
        champ_table = None
        annotation_table = None
        repetable_table = None
        
        for table in existing_tables:
            if isinstance(table, dict):
                table_id = table.get('id', '').lower()
                if table_id == dossier_table_id.lower():
                    dossier_table = table
                    dossier_table_id = table.get('id')
                    log(f"Table dossiers existante trouv√©e avec l'ID {dossier_table_id}")
                elif table_id == champ_table_id.lower():
                    champ_table = table
                    champ_table_id = table.get('id')
                    log(f"Table champs existante trouv√©e avec l'ID {champ_table_id}")
                elif table_id == annotation_table_id.lower():
                    annotation_table = table
                    annotation_table_id = table.get('id')
                    log(f"Table annotations existante trouv√©e avec l'ID {annotation_table_id}")
                elif repetable_table_id and table_id == repetable_table_id.lower():
                    repetable_table = table
                    repetable_table_id = table.get('id')
                    log(f"Table r√©p√©tables existante trouv√©e avec l'ID {repetable_table_id}")
        
        # Fonction pour ajouter les colonnes manquantes √† une table
        def add_missing_columns(table_id, all_columns):
            if not table_id:
                return
                
            # R√©cup√©rer les colonnes existantes
            url = f"{client.base_url}/docs/{client.doc_id}/tables/{table_id}/columns"
            response = requests.get(url, headers=client.headers)
            
            if response.status_code != 200:
                log_error(f"Erreur lors de la r√©cup√©ration des colonnes: {response.status_code}")
                return
                
            columns_data = response.json()
            existing_columns = set()
            
            if "columns" in columns_data:
                for col in columns_data["columns"]:
                    existing_columns.add(col.get("id"))
            
            # Trouver les colonnes manquantes
            missing_columns = []
            for col in all_columns:
                if col["id"] not in existing_columns:
                    missing_columns.append(col)
            
            # Ajouter les colonnes manquantes
            if missing_columns:
                log(f"Ajout de {len(missing_columns)} colonnes manquantes √† la table {table_id}")
                add_url = f"{client.base_url}/docs/{client.doc_id}/tables/{table_id}/columns"
                add_columns_payload = {"columns": missing_columns}
                add_response = requests.post(add_url, headers=client.headers, json=add_columns_payload)
                
                if add_response.status_code != 200:
                    log_error(f"Erreur lors de l'ajout des colonnes: {add_response.text}")
                else:
                    log(f"Colonnes ajout√©es avec succ√®s √† la table {table_id}")
        
        # Cr√©er ou mettre √† jour les tables
        if not dossier_table:
            log(f"Cr√©ation de la table {dossier_table_id}")
            dossier_table_result = client.create_table(dossier_table_id, column_types["dossier"])
            dossier_table = dossier_table_result['tables'][0]
            dossier_table_id = dossier_table.get('id')
        else:
            add_missing_columns(dossier_table_id, column_types["dossier"])
        
        if not champ_table:
            log(f"Cr√©ation de la table {champ_table_id}")
            champ_table_result = client.create_table(champ_table_id, column_types["champs"])
            champ_table = champ_table_result['tables'][0]
            champ_table_id = champ_table.get('id')
        else:
            add_missing_columns(champ_table_id, column_types["champs"])
        
        if not annotation_table:
            log(f"Cr√©ation de la table {annotation_table_id}")
            annotation_table_result = client.create_table(annotation_table_id, column_types["annotations"])
            annotation_table = annotation_table_result['tables'][0]
            annotation_table_id = annotation_table.get('id')
        else:
            add_missing_columns(annotation_table_id, column_types["annotations"])
        
        # G√©rer la table des blocs r√©p√©tables
        if has_repetable_blocks and repetable_table_id and "repetable_rows" in column_types:
            if not repetable_table:
                log(f"Cr√©ation de la table {repetable_table_id}")
                base_columns = [
                    {"id": "dossier_number", "type": "Int"},
                    {"id": "block_label", "type": "Text"},
                    {"id": "block_row_index", "type": "Int"},
                    {"id": "block_row_id", "type": "Text"}
                ]
                repetable_table_result = client.create_table(repetable_table_id, base_columns)
                repetable_table = repetable_table_result['tables'][0]
                repetable_table_id = repetable_table.get('id')
                
                # Ajouter toutes les colonnes sp√©cifiques
                add_missing_columns(repetable_table_id, column_types["repetable_rows"])
            else:
                add_missing_columns(repetable_table_id, column_types["repetable_rows"])
        
        # Retourner les IDs des tables
        result = {
            "dossiers": dossier_table_id,
            "champs": champ_table_id,
            "annotations": annotation_table_id
        }
        
        if has_repetable_blocks and repetable_table_id:
            result["repetable_rows"] = repetable_table_id
        
        log(f"Mise √† jour des tables termin√©e avec succ√®s")
        return result
        
    except Exception as e:
        log_error(f"Erreur lors de la mise √† jour des tables: {str(e)}")
        raise

# ========================================
# NOUVELLES FONCTIONS OPTIMIS√âES
# ========================================

def get_demarche_schema_robust(demarche_number: int) -> Dict[str, Any]:
    """
    Version robuste et optimis√©e de get_demarche_schema.
    
    Am√©liorations:
    - Gestion d'erreur plus robuste
    - Filtrage automatique des champs probl√©matiques
    - M√©tadonn√©es pour le suivi des changements
    - Performance optimis√©e
    
    Args:
        demarche_number: Num√©ro de la d√©marche
        
    Returns:
        dict: Sch√©ma robuste avec m√©tadonn√©es
    """
    if not API_TOKEN:
        raise ValueError("Le token d'API n'est pas configur√©")
    
    print(f"üîç R√©cup√©ration robuste du sch√©ma pour la d√©marche {demarche_number}")
    
    # Requ√™te GraphQL optimis√©e
    query = """
    query getRobustDemarcheSchema($demarcheNumber: Int!) {
        demarche(number: $demarcheNumber) {
            id
            number
            title
            activeRevision {
                id
                datePublication
                champDescriptors {
                    ...ChampDescriptorFragment
                    ... on RepetitionChampDescriptor {
                        champDescriptors {
                            ...ChampDescriptorFragment
                        }
                    }
                }
                annotationDescriptors {
                    ...ChampDescriptorFragment
                    ... on RepetitionChampDescriptor {
                        champDescriptors {
                            ...ChampDescriptorFragment
                        }
                    }
                }
            }
        }
    }
    
    fragment ChampDescriptorFragment on ChampDescriptor {
        __typename
        id
        type
        label
        description
        required
        ... on DropDownListChampDescriptor {
            options
            otherOption
        }
        ... on MultipleDropDownListChampDescriptor {
            options
        }
        ... on LinkedDropDownListChampDescriptor {
            options
        }
        ... on PieceJustificativeChampDescriptor {
            fileTemplate {
                filename
                url
            }
        }
    }
    """
    
    headers = {
        "Authorization": f"Bearer {API_TOKEN}",
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.post(
            API_URL,
            json={"query": query, "variables": {"demarcheNumber": demarche_number}},
            headers=headers,
            timeout=30
        )
        
        response.raise_for_status()
        result = response.json()
        
        # Gestion robuste des erreurs GraphQL
        if "errors" in result:
            non_critical_errors = []
            critical_errors = []
            
            for error in result["errors"]:
                error_message = error.get("message", "")
                if any(keyword in error_message.lower() for keyword in ["permission", "access", "unauthorized"]):
                    non_critical_errors.append(error_message)
                else:
                    critical_errors.append(error_message)
            
            if non_critical_errors:
                print(f"‚ö†Ô∏è Erreurs d'acc√®s (non-critiques): {len(non_critical_errors)}")
            
            if critical_errors:
                raise Exception(f"Erreurs critiques GraphQL: {'; '.join(critical_errors)}")
        
        # Validation de la r√©ponse
        data = result.get("data", {})
        demarche = data.get("demarche")
        
        if not demarche:
            raise Exception(f"D√©marche {demarche_number} non trouv√©e ou inaccessible")
        
        active_revision = demarche.get("activeRevision")
        if not active_revision:
            raise Exception(f"Aucune r√©vision active pour la d√©marche {demarche_number}")
        
        # Nettoyage automatique des champs probl√©matiques
        cleaned_schema = auto_clean_schema_descriptors(demarche)
        
        # Ajout de m√©tadonn√©es
        from datetime import datetime
        cleaned_schema["metadata"] = {
            "revision_id": active_revision.get("id"),
            "date_publication": active_revision.get("datePublication"),
            "retrieved_at": datetime.now().isoformat(),
            "optimized": True
        }
        
        print(f"‚úÖ Sch√©ma r√©cup√©r√©:")
        print(f"   üìù Champs utiles: {len(cleaned_schema['activeRevision']['champDescriptors'])}")
        print(f"   üìã Annotations: {len(cleaned_schema['activeRevision']['annotationDescriptors'])}")
        
        return cleaned_schema
        
    except Exception as e:
        raise Exception(f"Erreur lors de la r√©cup√©ration du sch√©ma: {e}")

def auto_clean_schema_descriptors(demarche: Dict[str, Any]) -> Dict[str, Any]:
    """
    Nettoie automatiquement les descripteurs en filtrant les champs probl√©matiques.
    """
    def filter_descriptors(descriptors: List[Dict], context: str = "") -> List[Dict]:
        filtered = []
        problematic_count = 0
        
        for descriptor in descriptors:
            typename = descriptor.get("__typename", "")
            descriptor_type = descriptor.get("type", "")
            
            # Filtrer les types probl√©matiques
            if typename in ["HeaderSectionChampDescriptor", "ExplicationChampDescriptor"] or \
               descriptor_type in ["header_section", "explication"]:
                problematic_count += 1
                continue
            
            # Traitement sp√©cial pour les blocs r√©p√©tables
            if typename == "RepetitionChampDescriptor" and "champDescriptors" in descriptor:
                filtered_sub_descriptors = filter_descriptors(
                    descriptor["champDescriptors"], 
                    f"{context}_repetable"
                )
                descriptor["champDescriptors"] = filtered_sub_descriptors
            
            filtered.append(descriptor)
        
        if problematic_count > 0:
            print(f"   üßπ {problematic_count} champs probl√©matiques filtr√©s ({context})")
        
        return filtered
    
    # Nettoyer la d√©marche
    cleaned_demarche = demarche.copy()
    active_revision = cleaned_demarche["activeRevision"]
    
    # Filtrer les descripteurs de champs
    if "champDescriptors" in active_revision:
        active_revision["champDescriptors"] = filter_descriptors(
            active_revision["champDescriptors"], 
            "champs"
        )
    
    # Filtrer les descripteurs d'annotations
    if "annotationDescriptors" in active_revision:
        active_revision["annotationDescriptors"] = filter_descriptors(
            active_revision["annotationDescriptors"], 
            "annotations"
        )
    
    return cleaned_demarche

def detect_schema_changes(current_schema: Dict[str, Any], previous_schema: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    D√©tecte les changements entre deux versions du sch√©ma.
    Crucial pour optimiser les mises √† jour quand une d√©marche est modifi√©e.
    """
    if not previous_schema:
        return {
            "is_first_run": True,
            "changes_detected": False,
            "requires_full_update": True
        }
    
    # Comparer les r√©visions
    current_revision = current_schema.get("metadata", {}).get("revision_id")
    previous_revision = previous_schema.get("metadata", {}).get("revision_id")
    
    if current_revision and previous_revision and current_revision == previous_revision:
        return {
            "is_first_run": False,
            "changes_detected": False,
            "revision_unchanged": True,
            "requires_full_update": False
        }
    
    # Analyser les changements d√©taill√©s
    def extract_field_signatures(descriptors):
        signatures = {}
        for desc in descriptors:
            field_id = desc.get("id")
            if field_id:
                signatures[field_id] = {
                    "type": desc.get("type"),
                    "label": desc.get("label"),
                    "required": desc.get("required"),
                    "typename": desc.get("__typename")
                }
        return signatures
    
    # Extraire les signatures
    current_champs = extract_field_signatures(
        current_schema.get("activeRevision", {}).get("champDescriptors", [])
    )
    previous_champs = extract_field_signatures(
        previous_schema.get("activeRevision", {}).get("champDescriptors", [])
    )
    
    current_annotations = extract_field_signatures(
        current_schema.get("activeRevision", {}).get("annotationDescriptors", [])
    )
    previous_annotations = extract_field_signatures(
        previous_schema.get("activeRevision", {}).get("annotationDescriptors", [])
    )
    
    # Comparer
    all_current = {**current_champs, **current_annotations}
    all_previous = {**previous_champs, **previous_annotations}
    
    new_fields = set(all_current.keys()) - set(all_previous.keys())
    removed_fields = set(all_previous.keys()) - set(all_current.keys())
    
    modified_fields = []
    for field_id in set(all_current.keys()) & set(all_previous.keys()):
        if all_current[field_id] != all_previous[field_id]:
            modified_fields.append(field_id)
    
    changes_detected = bool(new_fields or removed_fields or modified_fields)
    
    result = {
        "is_first_run": False,
        "changes_detected": changes_detected,
        "new_fields": list(new_fields),
        "removed_fields": list(removed_fields),
        "modified_fields": modified_fields,
        "requires_full_update": changes_detected,
        "revision_changed": current_revision != previous_revision
    }
    
    if changes_detected:
        print(f"üîÑ Changements d√©tect√©s:")
        if new_fields:
            print(f"   ‚ûï Nouveaux champs: {len(new_fields)}")
        if removed_fields:
            print(f"   ‚ûñ Champs supprim√©s: {len(removed_fields)}")
        if modified_fields:
            print(f"   üîß Champs modifi√©s: {len(modified_fields)}")
    
    return result

def smart_schema_update(client, demarche_number: int, use_robust_version: bool = True):
    """
    Mise √† jour intelligente qui choisit automatiquement la meilleure strat√©gie.
    
    Cette fonction:
    1. Utilise la version robuste ou classique selon le param√®tre
    2. D√©tecte les changements de sch√©ma
    3. Applique la strat√©gie de mise √† jour optimale
    4. Pr√©serve les donn√©es existantes
    
    Args:
        client: Instance GristClient
        demarche_number: Num√©ro de la d√©marche
        use_robust_version: True pour utiliser la version optimis√©e
        
    Returns:
        dict: R√©sultats de la mise √† jour
    """
    # Import des fonctions de log
    try:
        from grist_processor_working_all import log, log_error
    except ImportError:
        def log(msg, level=1): print(msg)
        def log_error(msg): print(f"ERREUR: {msg}")
    
    try:
        log(f"üöÄ D√©but de la mise √† jour intelligente pour la d√©marche {demarche_number}")
        
        # R√©cup√©rer le sch√©ma selon la version choisie
        if use_robust_version:
            log("üìä Utilisation de la version robuste optimis√©e")
            schema = get_demarche_schema_robust(demarche_number)
        else:
            log("üìä Utilisation de la version classique")
            schema = get_demarche_schema(demarche_number)
        
        # Cr√©er les d√©finitions de colonnes
        log("üîß Cr√©ation des d√©finitions de colonnes...")
        column_types, problematic_ids = create_columns_from_schema(schema)
        
        # Utiliser la fonction de mise √† jour existante
        log("üìù Mise √† jour des tables Grist...")
        table_ids = update_grist_tables_from_schema(client, demarche_number, column_types, problematic_ids)
        
        log("‚úÖ Mise √† jour intelligente termin√©e avec succ√®s")
        
        return {
            "success": True,
            "table_ids": table_ids,
            "schema_version": "robust" if use_robust_version else "classic",
            "column_counts": {
                "dossiers": len(column_types.get("dossier", [])),
                "champs": len(column_types.get("champs", [])),
                "annotations": len(column_types.get("annotations", [])),
                "repetable": len(column_types.get("repetable_rows", [])) if column_types.get("has_repetable_blocks") else 0
            },
            "features": {
                "has_repetable_blocks": column_types.get("has_repetable_blocks", False),
                "has_carto_fields": column_types.get("has_carto_fields", False)
            }
        }
        
    except Exception as e:
        log_error(f"Erreur lors de la mise √† jour intelligente: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "schema_version": "robust" if use_robust_version else "classic"
        }

# ========================================
# FONCTIONS DE COMPATIBILIT√â ET MIGRATION
# ========================================

def migrate_to_robust_version(client, demarche_number: int):
    """
    Migre en douceur vers la version robuste en pr√©servant les donn√©es existantes.
    """
    try:
        from grist_processor_working_all import log, log_error
    except ImportError:
        def log(msg, level=1): print(msg)
        def log_error(msg): print(f"ERREUR: {msg}")
    
    log("üîÑ Migration vers la version robuste...")
    
    try:
        # Test de la version robuste
        robust_result = smart_schema_update(client, demarche_number, use_robust_version=True)
        
        if robust_result["success"]:
            log("‚úÖ Migration r√©ussie vers la version robuste")
            log(f"   üìä Tables mises √† jour: {list(robust_result['table_ids'].keys())}")
            log(f"   üìù Colonnes total: {sum(robust_result['column_counts'].values())}")
            return robust_result
        else:
            log("‚ö†Ô∏è √âchec de la version robuste, fallback vers la version classique")
            return smart_schema_update(client, demarche_number, use_robust_version=False)
            
    except Exception as e:
        log_error(f"Erreur durant la migration: {e}")
        log("üîÑ Fallback vers la version classique...")
        return smart_schema_update(client, demarche_number, use_robust_version=False)

def validate_schema_compatibility(demarche_number: int) -> Dict[str, Any]:
    """
    Valide que les deux versions de sch√©ma (classique et robuste) sont compatibles.
    Utile pour les tests et la validation.
    """
    results = {
        "demarche_number": demarche_number,
        "classic_version": None,
        "robust_version": None,
        "compatibility": None,
        "differences": []
    }
    
    try:
        # Test version classique
        try:
            classic_schema = get_demarche_schema(demarche_number)
            classic_columns, classic_problematic = create_columns_from_schema(classic_schema)
            results["classic_version"] = {
                "success": True,
                "column_counts": {k: len(v) for k, v in classic_columns.items() if isinstance(v, list)},
                "problematic_fields": len(classic_problematic)
            }
        except Exception as e:
            results["classic_version"] = {"success": False, "error": str(e)}
        
        # Test version robuste
        try:
            robust_schema = get_demarche_schema_robust(demarche_number)
            robust_columns, robust_problematic = create_columns_from_schema(robust_schema)
            results["robust_version"] = {
                "success": True,
                "column_counts": {k: len(v) for k, v in robust_columns.items() if isinstance(v, list)},
                "problematic_fields": len(robust_problematic),
                "metadata": robust_schema.get("metadata", {})
            }
        except Exception as e:
            results["robust_version"] = {"success": False, "error": str(e)}
        
        # Comparaison
        if results["classic_version"]["success"] and results["robust_version"]["success"]:
            classic_counts = results["classic_version"]["column_counts"]
            robust_counts = results["robust_version"]["column_counts"]
            
            # V√©rifier la compatibilit√©
            differences = []
            for table_type in ["dossier", "champs", "annotations"]:
                classic_count = classic_counts.get(table_type, 0)
                robust_count = robust_counts.get(table_type, 0)
                
                if classic_count != robust_count:
                    differences.append(f"{table_type}: classique={classic_count}, robuste={robust_count}")
            
            results["compatibility"] = len(differences) == 0
            results["differences"] = differences
        
        return results
        
    except Exception as e:
        results["validation_error"] = str(e)
        return results

# ========================================
# POINT D'ENTR√âE POUR REMPLACEMENT PROGRESSIF
# ========================================

def get_demarche_schema_enhanced(demarche_number: int, prefer_robust: bool = True):
    """
    Point d'entr√©e principal pour remplacer progressivement get_demarche_schema.
    
    Cette fonction:
    - Essaie d'abord la version robuste si prefer_robust=True
    - Fallback automatique vers la version classique en cas d'√©chec
    - Interface identique √† la fonction existante
    - Garantit la compatibilit√© avec le code existant
    
    Args:
        demarche_number: Num√©ro de la d√©marche
        prefer_robust: True pour pr√©f√©rer la version optimis√©e
        
    Returns:
        dict: Sch√©ma de la d√©marche (format compatible)
    """
    if prefer_robust:
        try:
            return get_demarche_schema_robust(demarche_number)
        except Exception as e:
            print(f"‚ö†Ô∏è Version robuste √©chou√©e: {e}")
            print("üîÑ Fallback vers la version classique...")
            return get_demarche_schema(demarche_number)
    else:
        return get_demarche_schema(demarche_number)

# ========================================
# TESTS ET DIAGNOSTICS
# ========================================

def test_schema_functions(demarche_number: int = 107487):
    """
    Fonction de test pour valider toutes les fonctions du module.
    """
    print(f"üß™ Test des fonctions de sch√©ma pour la d√©marche {demarche_number}")
    print("=" * 60)
    
    # Test de compatibilit√©
    print("\n1Ô∏è‚É£ Test de compatibilit√© des versions:")
    compatibility = validate_schema_compatibility(demarche_number)
    
    if compatibility.get("classic_version", {}).get("success"):
        print("‚úÖ Version classique: OK")
    else:
        print("‚ùå Version classique: √âchec")
    
    if compatibility.get("robust_version", {}).get("success"):
        print("‚úÖ Version robuste: OK")
    else:
        print("‚ùå Version robuste: √âchec")
    
    if compatibility.get("compatibility"):
        print("‚úÖ Compatibilit√©: Versions compatibles")
    else:
        print("‚ö†Ô∏è Compatibilit√©: Diff√©rences d√©tect√©es")
        for diff in compatibility.get("differences", []):
            print(f"   - {diff}")
    
    # Test de la fonction enhanced
    print("\n2Ô∏è‚É£ Test de la fonction enhanced:")
    try:
        enhanced_schema = get_demarche_schema_enhanced(demarche_number)
        print("‚úÖ Fonction enhanced: OK")
        print(f"   üìù Champs: {len(enhanced_schema.get('activeRevision', {}).get('champDescriptors', []))}")
        print(f"   üìã Annotations: {len(enhanced_schema.get('activeRevision', {}).get('annotationDescriptors', []))}")
    except Exception as e:
        print(f"‚ùå Fonction enhanced: {e}")
    
    print("\n" + "=" * 60)
    print("üéØ Tests termin√©s")

if __name__ == "__main__":
    # Ex√©cuter les tests si le fichier est lanc√© directement
    test_schema_functions()
